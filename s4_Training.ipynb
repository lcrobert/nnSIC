{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check system info (CoLab used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7264,
     "status": "ok",
     "timestamp": 1550520467883,
     "user": {
      "displayName": "Kevin Liu",
      "photoUrl": "",
      "userId": "04481404945038253584"
     },
     "user_tz": -480
    },
    "id": "obI_D1o-SFFp",
    "outputId": "a8fe9a41-1d30-4da1-c8c8-655ed4f553b7"
   },
   "outputs": [],
   "source": [
    "print(\"CPU Status:\")\n",
    "!cat /proc/cpuinfo | grep model\\ name \n",
    "print(\"\\nDisk Status:\")\n",
    "!df -lh \n",
    "print(\"\\nRAM Status:\")\n",
    "!free -h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDd-mxY8mUMA"
   },
   "source": [
    "## Set GoogleDrivePath (CoLab used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3518,
     "status": "ok",
     "timestamp": 1550526822384,
     "user": {
      "displayName": "Kevin Liu",
      "photoUrl": "",
      "userId": "04481404945038253584"
     },
     "user_tz": -480
    },
    "id": "K3DkLq5TdjTc",
    "outputId": "f5664c9c-7577-49be-e185-fa33bfb6bcd4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)\n",
    "GDrivePath = os.path.join(os.getcwd(),'drive','My Drive')\n",
    "if os.path.exists(GDrivePath): \n",
    "   import sys\n",
    "   sys.path.append(GDrivePath)\n",
    "   print('GoogleDrive Ok')  \n",
    "else:\n",
    "   print ('GoogleDrive Failure') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILvr8cuRp7Tq"
   },
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1550525905407,
     "user": {
      "displayName": "Kevin Liu",
      "photoUrl": "",
      "userId": "04481404945038253584"
     },
     "user_tz": -480
    },
    "id": "kVYtIm2BRrvs",
    "outputId": "b633dab5-b316-4fe4-8c91-0f49c3ad677c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "from ReadTFRecords import InputDataPipeline as IDP \n",
    "from ModelTools import ConfusionMatrixAnalysis as CMA\n",
    "from ModelTools import PlotConfusionMatrix, FigToSummary\n",
    "print(\"\\nGPU Status:\")\n",
    "print (tf.test.gpu_device_name()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiqBYngMnvVr"
   },
   "source": [
    "## Build some  tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Biom3oPVRrv1"
   },
   "outputs": [],
   "source": [
    "def PlotAccLoss(result,save=False):\n",
    "    steps_per_epoch = data_size['train']/batch_size['train'] \n",
    "    epochs = [s/steps_per_epoch for s in result['step']] \n",
    "\n",
    "    fig1, ax1 = plt.subplots(num='Acc')\n",
    "    ax1.set_title('Accuracy',fontdict={'fontsize':20,'position':(0.5, 0.08)})\n",
    "    ax1.set_ylabel('Accuracy') \n",
    "    ax1.set_xlabel('Steps')    \n",
    "    ax1.plot(result['step'],result['train_acc'],'r-', label='train_acc')\n",
    "    ax1.plot(result['step'],result['vali_acc'],'b-', label='vali_acc')\n",
    "    ax1.tick_params(axis='x', labelcolor='k',direction='in')   \n",
    "    ax2 = ax1.twiny() # share same y axis\n",
    "    ax2.set_xlabel('Epochs',color='g')\n",
    "    ax2.plot(epochs,result['train_acc'],'r-', label='train_acc')\n",
    "    ax2.plot(epochs,result['vali_acc'],'b-', label='vali_acc')    \n",
    "    ax2.tick_params(axis='x', labelcolor='g',direction='in')\n",
    "    ax1.grid(which=\"both\", visible=False)\n",
    "    ax2.grid(which='both', visible=False)    \n",
    "    plt.ylim(0,1.1)\n",
    "    plt.legend(loc='best')\n",
    "    fig1.tight_layout()\n",
    "    if save: plt.savefig(os.path.join(save_main_path,'Acc.png'),bbox_inches='tight',dpi=150)     \n",
    "    plt.show()\n",
    "\n",
    "    fig3, ax3 = plt.subplots(num='Loss')\n",
    "    ax3.set_title('Loss',fontdict={'fontsize':20,'position':(0.5, 0.80)})\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax3.set_xlabel('Steps')    \n",
    "    ax3.plot(result['step'],result['train_loss'],'r-', label='train_loss')\n",
    "    ax3.plot(result['step'],result['vali_loss'],'b-', label='vali_loss')\n",
    "    ax3.tick_params(axis='x', labelcolor='k',direction='in')   \n",
    "    ax4 = ax3.twiny() \n",
    "    ax4.set_xlabel('Epochs',color='g')\n",
    "    ax4.plot(epochs,result['train_loss'],'r-', label='train_loss')\n",
    "    ax4.plot(epochs,result['vali_loss'],'b-', label='vali_loss')    \n",
    "    ax4.tick_params(axis='x', labelcolor='g',direction='in') \n",
    "    ax3.grid(which=\"both\", visible=False)\n",
    "    ax4.grid(which='both', visible=False)\n",
    "    plt.legend(loc='best')\n",
    "    fig1.tight_layout()\n",
    "    if save: plt.savefig(os.path.join(save_main_path,'Loss.png'),bbox_inches='tight',dpi=150)      \n",
    "    plt.show()\n",
    "      \n",
    "def SaveAccLossValue(result):\n",
    "    my_data_result = pd.DataFrame({\n",
    "                      \"step\": result['step'],\n",
    "                      \"train_acc\": result['train_acc'],  \n",
    "                      \"vali_acc\": result['vali_acc'],\n",
    "                      \"train_loss\": result['train_loss'],  \n",
    "                      \"vali_loss\": result['vali_loss'],                       \n",
    "                      })         \n",
    "    my_data_result.to_csv(os.path.join(save_main_path,'AccLossValue.csv'),sep=',') \n",
    "    \n",
    "def EpochStepConverter(numbers, unit, batch_size, data_size):\n",
    "    if unit=='step': # numbers*epochs_per_step\n",
    "       steps = numbers \n",
    "       epochs = numbers*(batch_size/data_size)        \n",
    "    elif unit=='epoch': # numbers*steps_per_epoch # step is element unit and  must be int\n",
    "       steps = numbers*round(data_size/batch_size)\n",
    "       epochs = numbers\n",
    "    else:\n",
    "       print (\"unit must be step or epoch\") \n",
    "       return 0, 0 \n",
    "    return steps, epochs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfjb2n8AmULo"
   },
   "source": [
    "## Build 1D-CNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIzHDWGamULq"
   },
   "outputs": [],
   "source": [
    "from CnnModelClass import Classifier # or import ClassifierM4 directly if don't need to rewrite model\n",
    "class ClassifierM4(Classifier): #1-D CNN\n",
    "    \n",
    "    def __init__(self, sess, **kwargs):        \n",
    "        self.sess = sess\n",
    "    \n",
    "    def input_layer(self, name=\"InputData\"): \n",
    "        \n",
    "        def img_profile(shape, pix_area): #[15,480,3]            \n",
    "            # luma(BT.709)=R*0.2126 + G*0.7152 + B*0.0722\n",
    "            # luma(BT.601)=R*0.299 + G*0.587 + B*0.114  \n",
    "            ysize, xsize = shape\n",
    "            #pix_gray = pix_area[:,:,:,0]*0.2126 + pix_area[:,:,:,1]*0.7152 + pix_area[:,:,:,2]*0.0722\n",
    "            pix_gray = pix_area[:,:,:,0]*0.333 + pix_area[:,:,:,1]*0.333 + pix_area[:,:,:,2]*0.333          \n",
    "            #print (pix_gray) #(?, 15, 480)\n",
    "            intensity = tf.reduce_sum(pix_gray, 1)/ysize \n",
    "            #print (intensity) #(?, 480)\n",
    "            return intensity   \n",
    " \n",
    "        with tf.name_scope(name):\n",
    "          self.x_img = tf.placeholder(tf.float32, [None, self.image_shape[0], self.image_shape[1], 3], name='x_img')     \n",
    "          self.x_img_profile = tf.reshape(img_profile(self.image_shape, self.x_img),[-1, self.image_shape[1] , 1], name=\"img2profile\") # NWC formet                                         \n",
    "          self.y_label = tf.placeholder(tf.uint8, [None, self.label_size],name='y_label')  \n",
    "                                        \n",
    "    def optimizer(self, learn_rate, true_label, pred_label, loss_name=\"Loss\"): \n",
    "        with tf.name_scope(loss_name):\n",
    "          self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=true_label, logits=pred_label))        \n",
    "        with tf.name_scope('Trainning_step'):\n",
    "          self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "          with tf.control_dependencies(self.update_ops):\n",
    "            #learn_rate = tf.cond(tf.less(self.loss, tf.constant(1.175)),lambda: 0.000000001,lambda: learn_rate)                                                 \n",
    "            self.train_step = tf.train.AdamOptimizer(learn_rate).minimize(self.loss)                                                                                           \n",
    "                                                 \n",
    "    def hidden_layers(self):                                        \n",
    "        self.conv1d_layer(input_neuro=self.x_img_profile, \n",
    "                          kernel_para=[5,1,self.convolution_kernel_size],\n",
    "                          name=\"Convolution1D_layer_1\")\n",
    "        self.conv1d_layer(input_neuro=self.conv, \n",
    "                          kernel_para=[15,self.convolution_kernel_size,self.convolution_kernel_size*2],\n",
    "                          name=\"Convolution1D_layer_2\")\n",
    "        self.conv1d_layer(input_neuro=self.conv, \n",
    "                          kernel_para=[45,self.convolution_kernel_size*2,self.convolution_kernel_size*2],\n",
    "                          name=\"Convolution1D_layer_3\")                                                 \n",
    "        self.conv1d_layer(input_neuro=self.conv, \n",
    "                          kernel_para=[90,self.convolution_kernel_size*2,self.convolution_kernel_size*3],\n",
    "                          name=\"Convolution1D_layer_4\")\n",
    "        self.conv1d_layer(input_neuro=self.conv, \n",
    "                          kernel_para=[105,self.convolution_kernel_size*3,self.convolution_kernel_size*3],\n",
    "                          name=\"Convolution1D_layer_5\")            \n",
    "        self.pooling_layer(input_neuro=self.conv, \n",
    "                           name=\"Pooling_2x1\", avg=False, one_d=True)                                                 \n",
    "        self.flatten(input_neuro=self.pool, \n",
    "                           name=\"Flatten\")  \n",
    "        self.fully_connected_layer(input_neuro=self.flatten ,\n",
    "                                   input_neuro_size=self.flatten_size,\n",
    "                                   output_neuro_size=self.fc_layer_neuro_size, \n",
    "                                   name=\"FullyConnected_Layer_1\")           \n",
    "        self.fully_connected_layer(input_neuro=self.fc ,\n",
    "                                   input_neuro_size=self.fc_layer_neuro_size,\n",
    "                                   output_neuro_size=int(self.fc_layer_neuro_size/2), \n",
    "                                   name=\"FullyConnected_Layer_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CswirDU5mULt"
   },
   "source": [
    "## Build training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzvAuUhgRrvy"
   },
   "outputs": [],
   "source": [
    "def RunTestSet(model, data, save=True, savepath = ''):     \n",
    "    image_batch, label_batch = data.feeder(data.test_iterator)                \n",
    "    test_accuracy, confusion_mtx = model.sess.run([model.accuracy,model.confusion],\n",
    "                                             feed_dict={model.x_img: image_batch*(1./255), \n",
    "                                                        model.y_label: label_batch,\n",
    "                                                        model.keep_prob: 1.0})\n",
    "    print (\"Test set Acc (Latest model) : %4.2f%%\"%(test_accuracy*100))\n",
    "    \n",
    "    if save: \n",
    "       savepath = os.path.join(save_main_path,'TestSetCM_LatestModel.png')\n",
    "       txt_savepath = os.path.join(save_main_path,'TestSetCM_LatestModel_Acc%4.2f.csv'%(test_accuracy*100))\n",
    "       np.savetxt(txt_savepath, confusion_mtx, delimiter=',', fmt=str(\"%d\"))\n",
    "                                   \n",
    "    cm_fig = PlotConfusionMatrix(confusion_mtx, show=True, savepath=savepath, colab=True)\n",
    "    cm_analysis = CMA(confusion_mtx)            \n",
    "    print (cm_analysis['report'])\n",
    "                                   \n",
    "    return confusion_mtx, cm_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em2Q6w6tRrwG"
   },
   "outputs": [],
   "source": [
    "def RunTraining(iter_number, earlystop=False, evalValiConfusion=False):  \n",
    "    \n",
    "    sess = tf.Session()            \n",
    "    data = IDP(sess,inputdata_path,batch_size,image_shape,label_size)    \n",
    "    model = ClassifierM4(sess) \n",
    "    model.init_model(image_shape, label_size, convolution_kernel_size,\n",
    "                     fc_layer_neuro_size, learn_rate, save_main_path)\n",
    "                          \n",
    "    # Set early_stop param (vali_loss based)\n",
    "    steps_per_epoch = round(data_size['train']/batch_size['train'])\n",
    "    #no_improvement_steps = 10*steps_per_epoch \n",
    "    no_improvement_steps = int(iter_number/3)\n",
    "    last_improvement_step = 0    \n",
    "    best_vali_loss = 99     \n",
    "    \n",
    "    # Init list of recording acc loss value (plot used) \n",
    "    record_steps = []\n",
    "    train_acc_val = []        \n",
    "    vali_acc_val = []   \n",
    "    train_loss_val = []        \n",
    "    vali_loss_val = []\n",
    "    \n",
    "    current_epoch = 0\n",
    "    steps = range(1,iter_number+1)\n",
    "    StartTime = datetime.now()      \n",
    "    for step in steps:        \n",
    "        # Optimize \n",
    "        image_batch, label_batch = data.feeder(data.train_iterator)\n",
    "        model.sess.run(model.train_step, \n",
    "                       feed_dict={model.x_img: image_batch*(1./255), \n",
    "                                  model.y_label: label_batch, \n",
    "                                  model.keep_prob: dropout,\n",
    "                                  model.training: True}) \n",
    "        \n",
    "        print (\"\\r\"+\"Epoch %4d : %3d/%3d \"%(current_epoch+1, step-current_epoch*steps_per_epoch, steps_per_epoch), end=\"\\r\")\n",
    "        \n",
    "        # Record acc and loss value of each 10 steps or 1 epoch \n",
    "        if step % 10 == 0 or step % (1*steps_per_epoch) == 0 or step == steps[-1]:\n",
    "           summary_train, train_loss, train_accuracy = model.sess.run([model.summary_merged_train, model.loss, model.accuracy],\n",
    "                                              feed_dict={model.x_img: image_batch*(1./255), \n",
    "                                                         model.y_label: label_batch,\n",
    "                                                         model.keep_prob: 1.0})\n",
    "           image_batch, label_batch = data.feeder(data.vali_iterator)     \n",
    "           summary_vali, vali_loss, vali_accuracy = model.sess.run([model.summary_merged_vali, model.loss, model.accuracy],\n",
    "                                              feed_dict={model.x_img: image_batch*(1./255), \n",
    "                                                         model.y_label: label_batch,\n",
    "                                                         model.keep_prob: 1.0}) \n",
    "           # Record acc loss value\n",
    "           record_steps.append(step)\n",
    "           train_acc_val.append(train_accuracy)       \n",
    "           vali_acc_val.append(vali_accuracy)           \n",
    "           train_loss_val.append(train_loss)       \n",
    "           vali_loss_val.append(vali_loss)                 \n",
    "           model.train_writer.add_summary(summary_train, step) \n",
    "           model.train_writer.add_summary(summary_vali, step)                   \n",
    "           ##show_info = 'Step: %d  Train_Acc: %4.2f%%  Vali_Acc: %4.2f%%  Train_Loss: %1.4f  Vali_Loss: %1.4f'%(step,train_accuracy*100,vali_accuracy*100,train_loss,vali_loss)       \n",
    "\n",
    "           # For each epoch\n",
    "           if step % (1*steps_per_epoch) == 0:\n",
    "              current_epoch += 1 \n",
    "              ##show_info = \">>> Epoch: %d  Vali_Acc: %4.2f%%  Vali_Loss: %1.4f\"%(current_epoch, vali_accuracy*100, vali_loss)                       \n",
    "              show_info = \"\\n\"+\"Train_Acc: %4.2f%%  Vali_Acc: %4.2f%%  Train_Loss: %1.4f  Vali_Loss: %1.4f \"%(train_accuracy*100,vali_accuracy*100,train_loss,vali_loss )              \n",
    "              if evalValiConfusion:   \n",
    "                 confusion_mtx = model.sess.run(model.confusion,\n",
    "                                             feed_dict={model.x_img: image_batch*(1./255), \n",
    "                                                        model.y_label: label_batch,\n",
    "                                                        model.keep_prob: 1.0})\n",
    "                 cm_fig = PlotConfusionMatrix(confusion_mtx, show=False, colab=True)\n",
    "                 cm_summery = FigToSummary(cm_fig,tag='ValiSet/ConfusionMatrix')\n",
    "                 model.train_writer.add_summary(cm_summery, current_epoch)\n",
    "                 cm_analysis = CMA(confusion_mtx)          \n",
    "                 weighted_avg = cm_analysis['weighted_avg'] # avg of precision, recall, f1 \n",
    "                 ##show_info = \">>> Epoch: %d  Vali_Acc: %4.2f%%  Vali_Loss: %1.4f  Precision: %4.2f%%  Recall: %4.2f%%\"%(current_epoch, vali_accuracy*100, vali_loss, weighted_avg[0]*100,weighted_avg[1]*100) \n",
    "                 show_info = \"\\n\"+\"Train_Acc: %4.2f%%  Vali_Acc: %4.2f%%  Train_Loss: %1.4f  Vali_Loss: %1.4f  Precision: %4.2f%%  Recall: %4.2f%%\"%(train_accuracy*100,vali_accuracy*100,train_loss,vali_loss,weighted_avg[0]*100,weighted_avg[1]*100)            \n",
    "              if vali_loss < best_vali_loss: \n",
    "                 best_vali_loss = vali_loss                 \n",
    "                 last_improvement_step = step # or epoch\n",
    "                 if earlystop: # (set false in colab)  \n",
    "                    model.saver_earlystop.save(model.sess, model_earlystop_savepath)\n",
    "              print (show_info)     \n",
    "           ##print (show_info)         \n",
    "\n",
    "        # EarlyStopping\n",
    "        if earlystop and step-last_improvement_step >= no_improvement_steps:\n",
    "           print(\"-------------------------------------------------------\")\n",
    "           print(\"No improvement found in a while, stopping optimization.\")\n",
    "           print(\"Stop at step : %d\"%(step))        \n",
    "           break      \n",
    "        \n",
    "    EndTime = datetime.now()\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Training completed!\")\n",
    "    print('Time usage : %s '%str(EndTime-StartTime))     \n",
    "    print(\"Final improvement step : %d  Vali_Loss %1.4f\"%(last_improvement_step,best_vali_loss))\n",
    "    model.train_writer.add_graph(model.sess.graph)                                      \n",
    "    model.train_writer.close() \n",
    "    model.saver.save(model.sess, model_savepath)        \n",
    "    print(\"-------------------------------------------------------\")   \n",
    "    confusion_mtx, cm_analysis = RunTestSet(model, data, save=True)      \n",
    "    model.sess.close()         \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    result = {'step':record_steps,\n",
    "              'train_acc':train_acc_val,\n",
    "              'vali_acc':vali_acc_val,\n",
    "              'train_loss':train_loss_val,\n",
    "              'vali_loss':vali_loss_val,\n",
    "              'test_cm':confusion_mtx,\n",
    "              'test_cm_report':cm_analysis,\n",
    "              'last_improvement_step':last_improvement_step}        \n",
    "    return result  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sluYD-2rmUL0"
   },
   "source": [
    "## Set training parameters (Local used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uX2jVUgBmUL1"
   },
   "outputs": [],
   "source": [
    "GDrivePath = os.path.join(os.getcwd())\n",
    "# Set static parameter \n",
    "input_main_path = os.path.join(GDrivePath,'InputData') \n",
    "save_main_path = os.path.join(GDrivePath,'OutputModel',datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
    "inputdata_path = {'train':os.path.join(input_main_path,'MyDataV4_train.tfrecords'),\n",
    "                  'vali':os.path.join(input_main_path,'MyDataV4_vali.tfrecords'),\n",
    "                  'test':os.path.join(input_main_path,'MyDataV4_test.tfrecords')}                \n",
    "model_savepath = os.path.join(save_main_path,'MyDataV4_m4')\n",
    "model_earlystop_savepath = os.path.join(save_main_path,'MyDataV4_m4_earlystop')    \n",
    "if not os.path.exists(save_main_path): os.makedirs(save_main_path)\n",
    "from ReadTFRecords import counter_TFRecord_datasize as ctd\n",
    "data_size = {'train':ctd(inputdata_path['train']),'vali':ctd(inputdata_path['vali']),'test':ctd(inputdata_path['test'])}                                         \n",
    "label_size = 7\n",
    "image_shape = [15,480]\n",
    "        \n",
    "# Set hyper parameter \n",
    "batch_size = {'train':125,'vali':data_size['vali'],'test':data_size['test']}\n",
    "learn_rate = 0.01 #0.0001 \n",
    "fc_layer_neuro_size = 1280 #  \n",
    "convolution_kernel_size = 32 #\n",
    "dropout = 0.7\n",
    "\n",
    "# Set steps or epochs\n",
    "steps, epochs = EpochStepConverter(45,'epoch',batch_size['train'],data_size['train'])\n",
    "#steps, epochs = EpochStepConverter(110,'step',batch_size['train'],data_size['train'])\n",
    "print (\"Iter steps = %d (%.2f epochs)\"%(steps,epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKvuxwhHmUL5"
   },
   "source": [
    "## Start training (Local used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMIaVH4hPMtV"
   },
   "outputs": [],
   "source": [
    "earlystop = True\n",
    "tf.reset_default_graph()\n",
    "result = RunTraining(steps, earlystop=earlystop, evalValiConfusion=True)\n",
    "PlotAccLoss(result,save=True)\n",
    "SaveAccLossValue(result)\n",
    "if earlystop and result['last_improvement_step'] != steps :\n",
    "   from QuickFunctions import PredTestSet\n",
    "   PredTestSet(model_earlystop_savepath, inputdata_path['test'], colab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HmD6jFhmUMF"
   },
   "source": [
    "## Set training parameters (CoLab used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1550537429479,
     "user": {
      "displayName": "Kevin Liu",
      "photoUrl": "",
      "userId": "04481404945038253584"
     },
     "user_tz": -480
    },
    "id": "F_pZhpOp4rs-",
    "outputId": "b7792f4b-ab0b-457c-982c-c94954714ee6"
   },
   "outputs": [],
   "source": [
    "# Set static parameter \n",
    "input_main_path = os.path.join(GDrivePath,'InputData') \n",
    "save_main_path = os.path.join(GDrivePath,'OutputModel',datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
    "inputdata_path = {'train':os.path.join(input_main_path,'MyDataV4_train.tfrecords'),\n",
    "                  'vali':os.path.join(input_main_path,'MyDataV4_vali.tfrecords'),\n",
    "                  'test':os.path.join(input_main_path,'MyDataV4_test.tfrecords')}                \n",
    "model_savepath = os.path.join(save_main_path,'MyDataV4_m4')\n",
    "#model_earlystop_savepath = os.path.join(save_main_path,'MyDataV1_m2_earlystop')    \n",
    "if not os.path.exists(save_main_path): os.makedirs(save_main_path)\n",
    "from ReadTFRecords import counter_TFRecord_datasize as ctd\n",
    "data_size = {'train':ctd(inputdata_path['train']),'vali':ctd(inputdata_path['vali']),'test':ctd(inputdata_path['test'])}                                         \n",
    "label_size = 7\n",
    "image_shape = [15,480]\n",
    "        \n",
    "# Set hyper parameter \n",
    "batch_size = {'train':200,'vali':data_size['vali'],'test':data_size['test']}\n",
    "learn_rate = 0.01 #0.0001 \n",
    "fc_layer_neuro_size = 1280 #  \n",
    "convolution_kernel_size = 32 #\n",
    "dropout = 0.6\n",
    "\n",
    "# Set steps or epochs\n",
    "steps, epochs = EpochStepConverter(200,'epoch',batch_size['train'],data_size['train'])\n",
    "#steps, epochs = EpochStepConverter(700,'step',batch_size['train'],data_size['train'])\n",
    "print (\"Iter steps = %d (%.2f epochs)\"%(steps,epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcUw_niYmUMK"
   },
   "source": [
    "## Start training (CoLab used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKNTHpIwmUML"
   },
   "outputs": [],
   "source": [
    "earlystop = False\n",
    "tf.reset_default_graph()\n",
    "result = RunTraining(steps, earlystop=earlystop, evalValiConfusion=True)\n",
    "PlotAccLoss(result,save=True)\n",
    "SaveAccLossValue(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxZ20rGiZpdT"
   },
   "source": [
    "## Pred. MyRealImgs (Reload latest model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBaEQ5MclJKH"
   },
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#import QuickFunctions \n",
    "#importlib.reload(QuickFunctions)\n",
    "from QuickFunctions import PredMyRealImgs\n",
    "#model_path = os.path.join(GDrivePath,'OutputModel', '201902100859','MyDataV2_m4') \n",
    "model_path = model_savepath \n",
    "imgfolder = os.path.join(GDrivePath,'RawData','MyRealImgs') \n",
    "PredMyRealImgs(model_path, imgfolder=imgfolder,colab=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred. MyRealImgs (Reload earlystoping model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QuickFunctions import PredMyRealImgs\n",
    "model_path = model_earlystop_savepath \n",
    "imgfolder = os.path.join(GDrivePath,'RawData','MyRealImgs') \n",
    "PredMyRealImgs(model_path, imgfolder=imgfolder,colab=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHTYmJ1qZVHD"
   },
   "source": [
    "## Model to .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3331,
     "status": "ok",
     "timestamp": 1550530283995,
     "user": {
      "displayName": "Kevin Liu",
      "photoUrl": "",
      "userId": "04481404945038253584"
     },
     "user_tz": -480
    },
    "id": "FMCW1l2VZNEt",
    "outputId": "5e1269ef-87fe-4b0b-a847-06b40aa95da4"
   },
   "outputs": [],
   "source": [
    "from s5_DeployPbFile import ModelToPB\n",
    "#model_path = os.path.join(GDrivePath,'OutputModel', '201902100859','MyDataV2_m4')\n",
    "model_path = model_savepath # model_earlystop_savepath \n",
    "pbfile_path = model_path+\".pb\"\n",
    "ModelToPB(model_path,pbfile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_RjEA5-GlLQ"
   },
   "source": [
    "## Save .ipynb by ctrl+s then Run the cell to copy file to save_main_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJgzBWz-9AJD"
   },
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "copy(os.path.join(GDrivePath,\"colab_used.ipynb\"),\n",
    "     os.path.join(save_main_path,\"Training.ipynb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ny6Vwpi0Ydz"
   },
   "source": [
    "## Pred. MyRealImgs (select other model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeWRF1VcswLY"
   },
   "outputs": [],
   "source": [
    "from QuickFunctions import PredMyRealImgs\n",
    "model_path = os.path.join(GDrivePath,'OutputModel', '201902082017','MyDataV1_m4')\n",
    "#model_path = model_path+\".pb\"\n",
    "imgfolder = os.path.join(GDrivePath,'RawData','MyRealImgs') \n",
    "PredMyRealImgs(model_path, imgfolder=imgfolder,colab=True) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mDd-mxY8mUMA",
    "ILvr8cuRp7Tq",
    "TiqBYngMnvVr",
    "qfjb2n8AmULo",
    "sluYD-2rmUL0",
    "UKvuxwhHmUL5",
    "jHTYmJ1qZVHD",
    "3ny6Vwpi0Ydz"
   ],
   "name": "colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
